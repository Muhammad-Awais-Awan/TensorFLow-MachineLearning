{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMneNfMNwET3vTlXlsNgapz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Awais-Awan/TensorFLow-MachineLearning/blob/main/Cloth%20Identifier%20Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MdEblck16y1h"
      },
      "outputs": [],
      "source": [
        "# Tensorflow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Helper Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset\n",
        "For this tutorial we will use the MINST Fashion Dataset. This is a dataset that is included in keras.\n",
        "This dataset includes 60,000 images for training and 10,000 images for validation/testing."
      ],
      "metadata": {
        "id": "d6lkuMy4tEFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist=keras.datasets.fashion_mnist # load dataset\n",
        "(train_images, train_labels), (test_images, test_labels)=fashion_mnist.load_data() #Split into testing and training"
      ],
      "metadata": {
        "id": "jB9x-Ln_tXnQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at this data to see what we are working with."
      ],
      "metadata": {
        "id": "Hqk6oaROt-w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3u4bGcque9d",
        "outputId": "04ad0952-50cb-4db3-e2bb-75fbc02e7576"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we've got 60,000 images that are made up of 28x28 pixels (784 in total)"
      ],
      "metadata": {
        "id": "eVUJCPvPukQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0,23,23] # lets have a look at one pixel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euxoB12FuzOO",
        "outputId": "369977e5-b069-4097-c8bc-293ae7053346"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pixel value are between 0 and 255, 0 being black and 255 being white. This means we have a grayscale image as there are no color channels."
      ],
      "metadata": {
        "id": "K3pp5LWpz18I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:10] # let's have a look at the first 10 training labels."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMxJZljKztH_",
        "outputId": "2c8a3958-58b8-4ace-af33-05cce3eeebcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our labels are integers ranging from 0-9. Each integer represents a specific article of clothing. We'll create an array of label names to indicate which is which."
      ],
      "metadata": {
        "id": "W4mXMnWb1ObT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=[\"T-shirt/top\",'Trouser','Pullover','Dress','Coat',\n",
        "             'Sandal','Shirt','Sneaker','Bag','Ankle boot']"
      ],
      "metadata": {
        "id": "U8tptbbe0d6X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, lets look at what some of these images look like!"
      ],
      "metadata": {
        "id": "JFf-rfRP0Xkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure() # make a figure\n",
        "plt.imshow(train_images[1000]) # getting the image\n",
        "plt.colorbar() # adding colorbar on the side\n",
        "plt.grid(False) # dont want grid\n",
        "plt.show() #showing the image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eVinhNlt1emU",
        "outputId": "b5c2d0f7-fa61-40e1-b8bb-599bb4034bb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing\n",
        "THe last step before creating our model is to preprocess our data. This simply means applying some prior transformations to our data before feeding it to the model. In this case we will simply scale all of our greyscale pixel values(0-255) to be between 0 and 1. We can do this by dividing each value in the training and testing sets by 255.0. We do this because smaller values will make it easier for the model to process our values."
      ],
      "metadata": {
        "id": "d5wLHVHJ1d5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0"
      ],
      "metadata": {
        "id": "HU92dCoreuK8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building the Model\n",
        "\n",
        "Now it's time to build the model! We are going to use keras sequential model with three different layers. This model represents a feed-forward neural network(one that passes values from left to right). We'll break down each layer and it's architecture below."
      ],
      "metadata": {
        "id": "WEuAKz6re5WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= keras.Sequential([ #Sequential is one of the most simplest form of neural network, in which just information going from left to right,passing through the layers sequentially\n",
        "    #inside here we are defining the no. of neurons for input layers for neural network\n",
        "    keras.layers.Flatten(input_shape=(28,28)), #input layer(1) : (Flatten) allow us to take in a shape of 28 of 28, and flatten all the pixels into 784 pixels. We took the 28x28 matrix and flatten it out.\n",
        "    \n",
        "    #Dense means every neuron of previous layer is connected to every neuron of this layer\n",
        "    #we have 128 neurons in next layer \"not have a answer why there are 128 neurons here\"\n",
        "    keras.layers.Dense(128,activation='relu'), #hidden layer(2) : Activation Function(relu) Rectifier Linear Unit if input +ve it output 1 and if input -ve it output 0.\n",
        "    \n",
        "    #Dense layer with 10 output neurons with activation function of \"softmax\"\n",
        "    # we have 10 neurons because we have total 10 classes to predict different values\n",
        "    keras.layers.Dense(10,activation='softmax') #output layer(3) Activation Function(softmax) will make sure that all of values of our neurons add up to one, and that  they are b/w 0 and 1.\n",
        "])"
      ],
      "metadata": {
        "id": "u5iIgD__hABG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compiling the Model(part of model building)\n",
        "The last step in building the model is to define the loss function, optimizer and meterics we would like to track. I won't go into detail about why we choose each of these right now."
      ],
      "metadata": {
        "id": "EQWWk7dklcXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This step and above step is called \"HYPER PARAMETER TRAINING\". these are all the parameters that we can change.\n",
        "\n",
        "model.compile(optimizer='adam', #adam is algorithm that performs the gradient descent\n",
        "              loss='sparse_categorical_crossentropy',# loss function\n",
        "              metrics=['accuracy'])# the output we want to see"
      ],
      "metadata": {
        "id": "ynDdb4IGlbmC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model\n",
        " Now its finaly time to train the model. Since we've already done all the work on our data this step is as easy as calling a single methode.\n",
        "This gives us a accuracy on training data"
      ],
      "metadata": {
        "id": "RbJ6ZlZTolLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images,train_labels,epochs=10) #we pass the data, labels and epochs and watch the magic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBnK357moPEP",
        "outputId": "27b50a17-8a53-469e-acf5-0ede2a711955"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5036 - accuracy: 0.8224\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3745 - accuracy: 0.8648\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3352 - accuracy: 0.8773\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3149 - accuracy: 0.8839\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2951 - accuracy: 0.8909\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2808 - accuracy: 0.8968\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2691 - accuracy: 0.8995\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2588 - accuracy: 0.9033\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2482 - accuracy: 0.9071\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2411 - accuracy: 0.9093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd613fa7090>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating the Model\n",
        "Now it's time to test/evaluate the model. We can do this quite easily using another builtin methode from keras.\n",
        "\n",
        "The verbose argument is defined from the keras documentation as \"verbose:0 or 1. Verbosity mode.0=silent, 1=progress bar.\""
      ],
      "metadata": {
        "id": "v58qu9RDp6xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc= model.evaluate(test_images,test_labels,verbose=1)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3a2IM1_pu3x",
        "outputId": "640feedc-90b6-45b6-83fb-501d9f91ba73"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8823\n",
            "Test accuracy: 0.8823000192642212\n"
          ]
        }
      ]
    }
  ]
}